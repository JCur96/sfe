---
title: "my-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{my-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# sfe (Simple Feature, Ecology)
## A Walkthrough Guide With a Test Case

### A Breif Note about Dependencies
sfe was built in Ubuntu 18.04, and tested in Windows 10, so should work across
operating systems. However initial setup on Linux machines can be fairly complicated.

Here I shall give a brief guide on how to get things running on a Linux machine.
Start by running the command `install.packages("rgdal")` in R and watch to make 
sure it does actually install. If it doesn't its likely because the UbunutuGIS 
repository isn't signed so you will have to manually add this to trusted sources. 
Please see apt-secure(8) manpage and sources.list(5) manpage for details on what 
this actually means before moving on to the next section and doing that with 
the following commands on Linux terminal;
```
sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable 
    && sudo apt-get update
sudo gedit /etc/apt/sources.list.d/ubuntugis-ubuntu-ubuntu-ubuntugis-unstable-bionic.list
```
The second command will open a text document, where you must set a trusted = yes
flag. That looks like this; 
`deb [trusted=yes] http://ppa.launchpad.net/ubuntugis/ubuntugis-unstable/ubuntu bionic main`

Next step is to coerce Ubuntu into finding the gdal-config file which R and 
python3 need to install their versions of gdal. The following helped me work out what went wrong:
https://stackoverflow.com/questions/12141422/error-gdal-config%20-not-found 

If you don't want to read that, the following commands solved that issue for me,
and hopefully will for you too;
```
apt-file search gdal-config
sudo apt-get install libgdal1-dev
sudo apt-get update 
sudo apt-get upgrade
```
After running all of that rgdal should install in the usual way.
Next you may want to install rgeos manually, as this was another package I had 
issues with. to do that run `install.packages("rgeos")` in R followed by 
`sudo apt-get install libgeos-c1v5` on Linux Terminal. Re-run 
`install.packages("rgeos")` and you should be in business.

The final dependency you should install previous to trying to use sfe is `devtools`
This one is easy to install, simply running `install.packages("devtools")` should
be sufficient. 

## Installing sfe
In R run the command `devtools::install_github("JCur96/sfe", force =T)` followed
by
```{r setup}
library(sfe)
library(rgeos)
library(rgdal)
```
The package is now loaded and ready for use. 

## A walkthrough With a Test Case
Here I will run through the exact code I have used in my Masters Thesis as a 
demonstration of how to use this package. The test case I'm looking at are the 
Pangolins, that is species of the order Pholidota.

The NHM data can be kept under version control using datastorr and potentially 
downloaded with this package, however that data is currently proprietry so will 
be read off of my machine locally in this example.
For a more comprehensive overview of how to use datastorr please see the vignette
on https://github.com/ropenscilabs/datastorr
Initially setting up datastorr can be slightly difficult, but it boils down to 
running this command;
`datastorr:::autogenerate(repo="JCur96/sfe", read="read.csv")` which produces 
several functions which are then used for data management, and then making an 
initial release of the data. 
I will give a brief example of how to use those functions here out of 
interest; 
```{r}
# First it is advisable that you check if you've got the data already
sfe::mydata_versions()
# If not, you can check what versions are avaliable on GitHub
sfe::mydata_versions(local=F)
# From those you can choose a version you wish to work with
myFakePangolinData <- sfe::mydata(version = '0.0.1')
# Once you've made any edits to the data you can upload it to version control
sfe::updateVersion()
# UpdateVersion helps you update the description file before you make a new release
sfe::mydata_release()
```

First I read in the data from both Natural History Museum(NHM) and the IUCN.
```{r}
NHM_Pangolins <- read.csv("../data/NHMPangolins.csv", header=T)
IUCN <- inReadOld()

```

Then I wrangle the data. This involves changing a key column to 
"binomial" as many of the functions to follow rely on the data having a column of
species names under the column header of "binomial". It also involves removing 
spaces from between binomial names, and filtering out blank or NA values from
other key columns, as well as converting both data frames to the sf format, 
making sure both are projected in latitude and longitude. 

```{r}
NHM_Pangolins <- prepNHMData(NHM_Pangolins)
# To prove that this has done what we want, we can view the first ten rows
head(NHM_Pangolins)
IUCN <- prepIUCNData(IUCN)
head(IUCN)
```
Theres a lot of extra information in the IUCN data sets, but I won't filter that
out, depending on what you are doing different parts will be useful, and I cannot
devise an algorith to usefully sort that for every case.

I then filter both data sets to contain only species entries which occur in both
data sets. This function will reassign the IUCN data to the global environemnt
but with only matching species. I did this as a substitute for being able to 
return two objects from a function in R. 
```{r}
NHM_Pangolins <- matchBinomial(NHM_Pangolins, IUCN)

```

And can unify some naming conventions of Type, if the data has that information;
```{r}
NHM_Pangolins <- fixTypeNames(NHM_Pangolins)
```

Now that the data has been reduced to only usable records I can get into the meat 
of the functions I've writte; adding error to point data and converting that data
into convex hulls. 
```{r}
NHM_Pangolins <- addError(NHM_Pangolins)
```

At this point I thought it would be useful to explore the data visually, both 
out of interest and to doube check that I really was converting point data into
point-radius data.
```{r}
# This function plots maps, but does not display them, it plots and saves them
# in a pre-made destination folder which you are prompted to enter the path to 
# when you run this funciton. This both saves computer time and memory, whilst 
# allowing you as the user to browse all the maps at your leisure. 
plotMaps(NHM_Pangolins, IUCN)
```
Not all maps will seem to show anything interesting, but that is mostly due to 
the scale of the maps versus the scale of the species ranges in some cases. 
Correctly scaling the maps is quite difficult as I am dealing with global 
distributions, whereas some range records seem to indicate a range of just a 
handful of kilometers. 

Some of these maps show range overlap, but what kind of percentage?
The next set of functions calculate percentage overlap between point-radius or 
convex hull data, depending on whether the user has utilised the convex hull 
generating functions yet or not. 
```{r}
NHM_Pangolins <- calculateOverlaps(NHM_Pangolins, IUCN)
```

The above function will return the NHM data frame with a `Percent_overlap` column
added, the contents of which is calculated from the geometry column of the data.

The geometry column could either be point-radius or a fully realised convex hull,
which can be created and tailored using the following functions; 

```{r}
# This first function creates convex hulls, without any clipping to landmasses
NHM_Pangolins <- makeConvexHulls(NHM_Pangolins)
# And this function takes those hulls and clips them to landmasses 
NHM_Pangolins <- clipHullsToLand(NHM_Pangolins)

#If you know you want hulls which are clipped to landmasses from the start you 
# can use the following function
NHM_Pangolins <- makeLandClippedHulls(NHM_Pangolins)
```

All of the above will give a percentage overlap with IUCN convex hulls, but for 
analysis percentage is a tricky thing to work with, so I have created another 
function to flatten the data to binomial (1 or 0) data, which makes modelling 
with this data much easier.
```{r}
NHM_Pangolins <- binomialOverlap(NHM_Pangolins)
```
This function changes the `Percent_overlap` column to `binomial_overlap` as well
as flatten the data. 

I have also created a function for calculating the distance between the centroid 
of the NHM data and the edge of the IUCN data, as I feel that this distance might
be of interest with regards to analysis and modelling, and does not requrie any
flattening to use. 
```{r}
NHM_Pangolins <- centroidEdgeDistance(NHM_Pangolins, IUCN)
```

This returns the NHM data frame with added an added distance column (and a 
distance2 column, as there are a few IUCN records with two range polygons, and 
without this inclusion the function will not run). 

------

The above test case gives a run through of all of the functions included in this
package, below I shall continue with the analysis of the test case, however none
of the functions below are of my creation, so I will not be offering much in the 
way of tutorial. 

## Analysing The Output

To analyse what I have generated I will need to use mixed effect models. I am 
familiar with lme4 and lmerTest, so I will use those packages, however any mixed
effect package should be sufficent. 
```{r}
install.packages('lme4')
install.packages('lmerTest')
library(lme4)
library(lmerTest)
```

In theory, the data have now been treated in such a way that constructing the 
models that I wish to explore will be extremely simple. 

```{r}
binomialModel <- glmer()
distanceModel <- glmer()
